La arquitectura que te recomendaron parece adecuada:

Capa de entrada: 63 neuronas (para los landmarks de MediaPipe)
Capas ocultas: 128 y 64 neuronas
Capa de salida: 29 neuronas con activaci√≥n softmax

Enfoque t√©cnico

Preprocesamiento:

Usar MediaPipe Hands para extraer los 21 puntos clave (landmarks) de la mano
Cada landmark tiene coordenadas x, y, z (63 valores en total)
Normalizar las coordenadas para mayor robustez


Modelo:

Red neuronal como la que mencionaste con PyTorch o TensorFlow


Interfaz:

Aplicaci√≥n web sencilla con Flask que capture video y muestre las predicciones


INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
üîé Esto indica que TensorFlow usar√° una optimizaci√≥n llamada XNNPACK (una librer√≠a de ejecuci√≥n optimizada para CPU) al ejecutar modelos en formato .tflite (modelo ligero, para dispositivos como m√≥viles o embebidos).

Aunque no est√©s usando expl√≠citamente .tflite, esto puede salir al usar alguna operaci√≥n acelerada de bajo nivel.

üìä Resumen del entrenamiento y desempe√±o del modelo
Tu modelo est√° haciendo clasificaci√≥n de lenguaje de se√±as (ASL) con clases desde A a Z, m√°s otras (space, nothing, delete).

üöÄ Proceso de entrenamiento:
Muestras del dataset: 2,422

√âpocas: 20

Mejor precisi√≥n de validaci√≥n: 52.62%

Precisi√≥n final en test: 48.90%

üìâ Evoluci√≥n del entrenamiento:
El modelo comenz√≥ con un rendimiento bajo (como es normal), pero fue mejorando poco a poco.

Esto muestra un aprendizaje progresivo, sin sobreentrenamiento aparente.

üìâ M√©tricas por clase:
Hay clases con desempe√±o muy alto, como Z, H, C, W (con F1-score > 0.8).

Pero muchas clases tienen F1-score de 0.0, es decir, no se est√°n reconociendo correctamente, como D, F, G, M, N, P, etc.

Esto sugiere que tu modelo tiene desbalance de datos o dificultad para distinguir gestos similares.

üìÅ ¬øQu√© significa "Modelo guardado como modelo_asl.pkl"?
Est√°s guardando el modelo con joblib o pickle como un archivo serializado en Python (.pkl). Esto es t√≠pico cuando usas modelos que no son puramente Keras, o cuando quieres cargar el modelo con una interfaz personalizada m√°s adelante.



¬°Hola! Entendiendo tu inter√©s en la detecci√≥n de letras en lenguaje de se√±as utilizando coordenadas, exploremos c√≥mo las funciones ReLU y sigmoide podr√≠an influir en el rendimiento de un modelo de aprendizaje profundo para esta tarea.

Funci√≥n de Activaci√≥n ReLU (Rectified Linear Unit)
La funci√≥n ReLU es una de las funciones de activaci√≥n m√°s populares en las redes neuronales profundas. Su —Ñ–æ—Ä–º—É–ªa es simple:

f(x)=max(0,x)

Ventajas de ReLU para la detecci√≥n de letras en lenguaje de se√±as:

Eficiencia computacional: ReLU es computacionalmente muy eficiente ya que solo involucra una operaci√≥n de comparaci√≥n y un m√°ximo. Esto puede acelerar el entrenamiento del modelo, lo cual es importante cuando se trabaja con datos de video o en tiempo real para el lenguaje de se√±as.
Evita el problema del desvanecimiento del gradiente: Para valores positivos, la pendiente de ReLU es constante (1), lo que ayuda a mitigar el problema del desvanecimiento del gradiente que puede ocurrir en redes profundas y dificulta el aprendizaje. Esto es crucial para modelos complejos que podr√≠an ser necesarios para reconocer las sutilezas de las se√±as.
Introduce dispersidad: ReLU establece a cero las activaciones para entradas negativas. Esta dispersidad puede llevar a representaciones m√°s concisas y potencialmente a una mejor generalizaci√≥n del modelo, enfoc√°ndose en las caracter√≠sticas m√°s relevantes de las coordenadas de la mano.
Desventajas de ReLU:

Problema de la neurona "muerta" (Dying ReLU): Si una neurona ReLU recibe consistentemente entradas negativas, su salida ser√° siempre cero y su gradiente tambi√©n ser√° cero. Esto significa que la neurona deja de aprender y puede quedar "muerta". Esto podr√≠a ser un problema si las coordenadas de la mano generan consistentemente valores negativos en algunas neuronas.
Funci√≥n de Activaci√≥n Sigmoide (Funci√≥n Log√≠stica)
La funci√≥n sigmoide tiene la siguiente —Ñ–æ—Ä–º—É–ªa:

œÉ(x)= 
1+e 
‚àíx
 
1
‚Äã
 

Su salida se encuentra en el rango de (0, 1), lo que hist√≥ricamente la hizo popular para problemas de clasificaci√≥n binaria donde la salida pod√≠a interpretarse como una probabilidad.

Ventajas de la funci√≥n sigmoide (potenciales, aunque limitadas para esta tarea):

Salida acotada: La salida entre 0 y 1 podr√≠a interpretarse como un nivel de confianza en la detecci√≥n de una caracter√≠stica particular basada en las coordenadas.
Suavidad y diferenciabilidad: La sigmoide es suave y diferenciable en todo su dominio, lo que la hace compatible con el algoritmo de retropropagaci√≥n utilizado para entrenar redes neuronales.
Desventajas de la funci√≥n sigmoide para la detecci√≥n de letras en lenguaje de se√±as:

Problema del desvanecimiento del gradiente: La sigmoide sufre significativamente del problema del desvanecimiento del gradiente, especialmente en capas profundas. A medida que la magnitud de la entrada se aleja de cero (hacia valores muy positivos o muy negativos), el gradiente de la sigmoide se acerca a cero, lo que ralentiza o detiene el aprendizaje. Esto es una limitaci√≥n importante para redes complejas necesarias para el reconocimiento de lenguaje de se√±as.
Salida no centrada en cero: La salida de la sigmoide est√° entre 0 y 1, lo que puede llevar a un aprendizaje menos eficiente en capas posteriores de la red.
Computacionalmente m√°s costosa: Calcular la funci√≥n exponencial en la sigmoide es m√°s costoso computacionalmente que la simple comparaci√≥n de ReLU.
Uso para Tomar Coordenadas para Detectar Letras en Lenguaje de Se√±as
Cuando se utilizan coordenadas de la mano (por ejemplo, obtenidas mediante MediaPipe u otras t√©cnicas de seguimiento de manos) como entrada para un modelo de aprendizaje profundo para detectar letras en lenguaje de se√±as, la elecci√≥n de la funci√≥n de activaci√≥n es crucial.

Consideraciones espec√≠ficas para esta tarea:

Naturaleza de los datos: Las coordenadas de la mano son valores continuos. No est√°n inherentemente limitados a un rango de 0 a 1.
Complejidad de los gestos: El lenguaje de se√±as involucra gestos complejos y sutiles que pueden requerir redes neuronales profundas para aprender las caracter√≠sticas relevantes de las trayectorias y poses de las manos.
¬øCu√°l funci√≥n es m√°s adecuada?

En general, ReLU o sus variantes (como Leaky ReLU o Parametric ReLU) ser√≠an m√°s adecuadas que la funci√≥n sigmoide para las capas ocultas de un modelo de aprendizaje profundo dise√±ado para detectar letras en lenguaje de se√±as a partir de coordenadas de la mano.

Razones:

Superaci√≥n del desvanecimiento del gradiente: La profundidad de la red probablemente ser√° importante para capturar las complejidades del lenguaje de se√±as, y ReLU ayuda a entrenar redes m√°s profundas de manera m√°s efectiva.
Eficiencia computacional: El procesamiento en tiempo real podr√≠a ser un objetivo, y ReLU es m√°s r√°pido de calcular.
Aprendizaje de caracter√≠sticas: La capacidad de ReLU para inducir dispersidad puede ayudar al modelo a enfocarse en las caracter√≠sticas m√°s discriminativas de las coordenadas de la mano para diferenciar entre letras.
¬øCu√°ndo podr√≠a usarse la sigmoide?

La funci√≥n sigmoide podr√≠a ser apropiada en la capa de salida si el objetivo es una clasificaci√≥n binaria (por ejemplo, ¬øes esta se√±a la letra 'A' o no?). En este caso, la salida de la sigmoide podr√≠a interpretarse como la probabilidad de que la se√±a sea la letra 'A'. Sin embargo, para una clasificaci√≥n multiclase (identificar cu√°l de las 27 letras del alfabeto de se√±as es), se usar√≠a m√°s com√∫nmente la funci√≥n softmax en la capa de salida, que generaliza la sigmoide para m√∫ltiples clases y proporciona una distribuci√≥n de probabilidad sobre todas las clases.

En resumen:

Para las capas intermedias (ocultas) de tu modelo de detecci√≥n de letras en lenguaje de se√±as basado en coordenadas, ReLU o sus variantes son probablemente una mejor opci√≥n debido a su capacidad para mitigar el desvanecimiento del gradiente y su eficiencia computacional. La sigmoide es menos adecuada para las capas ocultas en redes profundas debido al problema del desvanecimiento del gradiente. Podr√≠as considerar la sigmoide (para clasificaci√≥n binaria) o m√°s probablemente softmax (para clasificaci√≥n multiclase) en la capa de salida dependiendo de la tarea espec√≠fica.


Carga de modelo numero 2
hablame mejor de estos resultados:
Procesando clase: A
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
Procesando clase: B
Procesando clase: C
Procesando clase: D
Procesando clase: E
Procesando clase: F
Procesando clase: G
Procesando clase: H
Procesando clase: I
Procesando clase: J
Procesando clase: K
Procesando clase: L
Procesando clase: M
Procesando clase: N
Procesando clase: O
Procesando clase: P
Procesando clase: Q
Procesando clase: R
Procesando clase: S
Procesando clase: T
Procesando clase: U
Procesando clase: V
Procesando clase: W
Procesando clase: X
Procesando clase: Y
Procesando clase: Z
Procesando clase: space
Procesando clase: nothing
Dataset cargado: 61975 muestras
Epoch 1/20, Train Loss: 3.1237, Train Acc: 32.94%, Val Loss: 2.8956, Val Acc: 58.50%
Modelo guardado con precisi n de validaci n: 58.50%
Epoch 2/20, Train Loss: 2.8546, Train Acc: 60.23%, Val Loss: 2.7958, Val Acc: 63.70%
Modelo guardado con precisi n de validaci n: 63.70%
Epoch 3/20, Train Loss: 2.7727, Train Acc: 66.89%, Val Loss: 2.7294, Val Acc: 70.11%
Modelo guardado con precisi n de validaci n: 70.11%
Epoch 4/20, Train Loss: 2.7388, Train Acc: 69.69%, Val Loss: 2.7002, Val Acc: 73.02%
Modelo guardado con precisi n de validaci n: 73.02%
Epoch 5/20, Train Loss: 2.7133, Train Acc: 71.96%, Val Loss: 2.6979, Val Acc: 72.92%
Epoch 6/20, Train Loss: 2.7035, Train Acc: 72.76%, Val Loss: 2.6907, Val Acc: 73.56%
Modelo guardado con precisi n de validaci n: 73.56%
Epoch 7/20, Train Loss: 2.6785, Train Acc: 75.28%, Val Loss: 2.6556, Val Acc: 77.05%
Modelo guardado con precisi n de validaci n: 77.05%
Epoch 8/20, Train Loss: 2.6673, Train Acc: 76.27%, Val Loss: 2.6563, Val Acc: 76.99%
Epoch 9/20, Train Loss: 2.6629, Train Acc: 76.58%, Val Loss: 2.6506, Val Acc: 77.48%
Modelo guardado con precisi n de validaci n: 77.48%
Epoch 10/20, Train Loss: 2.6607, Train Acc: 76.79%, Val Loss: 2.6528, Val Acc: 77.21%
Epoch 11/20, Train Loss: 2.6588, Train Acc: 76.87%, Val Loss: 2.6544, Val Acc: 77.13%
Epoch 12/20, Train Loss: 2.6560, Train Acc: 77.14%, Val Loss: 2.6519, Val Acc: 77.33%
Epoch 13/20, Train Loss: 2.6545, Train Acc: 77.26%, Val Loss: 2.6495, Val Acc: 77.57%
Modelo guardado con precisi n de validaci n: 77.57%
Epoch 14/20, Train Loss: 2.6538, Train Acc: 77.32%, Val Loss: 2.6489, Val Acc: 77.58%
Modelo guardado con precisi n de validaci n: 77.58%
Epoch 15/20, Train Loss: 2.6533, Train Acc: 77.31%, Val Loss: 2.6503, Val Acc: 77.44%
Epoch 16/20, Train Loss: 2.6382, Train Acc: 78.88%, Val Loss: 2.6289, Val Acc: 79.65%
Modelo guardado con precisi n de validaci n: 79.65%
Epoch 17/20, Train Loss: 2.6315, Train Acc: 79.55%, Val Loss: 2.6271, Val Acc: 79.80%
Modelo guardado con precisi n de validaci n: 79.80%
Epoch 18/20, Train Loss: 2.6298, Train Acc: 79.72%, Val Loss: 2.6301, Val Acc: 79.60%
Epoch 19/20, Train Loss: 2.6287, Train Acc: 79.79%, Val Loss: 2.6267, Val Acc: 79.85%
Modelo guardado con precisi n de validaci n: 79.85%
Epoch 20/20, Train Loss: 2.6295, Train Acc: 79.66%, Val Loss: 2.6249, Val Acc: 80.00%
Modelo guardado con precisi n de validaci n: 80.00%
Precisi n del modelo en el conjunto de prueba: 81.25%
Clase A - Precisi n: 0.7664, Recall: 0.9820, F1-Score: 0.8609
Clase B - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase C - Precisi n: 0.9903, Recall: 0.9968, F1-Score: 0.9935
Clase D - Precisi n: 0.9715, Recall: 0.9615, F1-Score: 0.9665
Clase E - Precisi n: 0.8214, Recall: 0.9914, F1-Score: 0.8984
Clase F - Precisi n: 0.6841, Recall: 0.9954, F1-Score: 0.8109
Clase G - Precisi n: 0.9829, Recall: 0.9853, F1-Score: 0.9841
Clase H - Precisi n: 0.9803, Recall: 0.9971, F1-Score: 0.9887
Clase I - Precisi n: 0.9968, Recall: 0.9360, F1-Score: 0.9654
Clase J - Precisi n: 0.9974, Recall: 0.9701, F1-Score: 0.9836
Clase K - Precisi n: 0.8323, Recall: 0.9900, F1-Score: 0.9043
Clase L - Precisi n: 0.6135, Recall: 1.0000, F1-Score: 0.7604
Clase M - Precisi n: 0.5000, Recall: 0.9526, F1-Score: 0.6558
Clase N - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase O - Precisi n: 0.9538, Recall: 1.0000, F1-Score: 0.9763
Clase P - Precisi n: 1.0000, Recall: 0.9085, F1-Score: 0.9520
Clase Q - Precisi n: 0.9420, Recall: 0.9969, F1-Score: 0.9687
Clase R - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase S - Precisi n: 0.9651, Recall: 0.9730, F1-Score: 0.9690
Clase T - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase U - Precisi n: 0.3565, Recall: 0.9836, F1-Score: 0.5233
Clase V - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase W - Precisi n: 0.8800, Recall: 0.9670, F1-Score: 0.9215
Clase X - Precisi n: 0.9551, Recall: 0.9785, F1-Score: 0.9667
Clase Y - Precisi n: 1.0000, Recall: 1.0000, F1-Score: 1.0000
Clase Z - Precisi n: 0.9942, Recall: 0.9799, F1-Score: 0.9870
Clase space - Precisi n: 0.8949, Recall: 0.9841, F1-Score: 0.9374
Clase delete - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase nothing - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Modelo guardado como modelo_asl.pkl


cambios para la siguiente prueba 40 epocas
[Running] python -u "c:\Users\mau_l\OneDrive\Documentos\IA\Proyecto II\Modelo.py"
Procesando clase: A
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
Procesando clase: B
Procesando clase: C
Procesando clase: D
Procesando clase: E
Procesando clase: F
Procesando clase: G
Procesando clase: H
Procesando clase: I
Procesando clase: J
Procesando clase: K
Procesando clase: L
Procesando clase: M
Procesando clase: N
Procesando clase: O
Procesando clase: P
Procesando clase: Q
Procesando clase: R
Procesando clase: S
Procesando clase: T
Procesando clase: U
Procesando clase: V
Procesando clase: W
Procesando clase: X
Procesando clase: Y
Procesando clase: Z
Procesando clase: space
Procesando clase: nothing
Dataset cargado: 61975 muestras

==================================================
Fold 1/5
==================================================

--- Entrenando Fold 1 ---
Epoch 1/20, Train Loss: 3.0790, Train Acc: 37.78%, Val Loss: 2.8325, Val Acc: 62.61%
Modelo guardado para Fold 1 con precisi n de validaci n: 62.61%
Epoch 2/20, Train Loss: 2.8109, Train Acc: 64.04%, Val Loss: 2.7406, Val Acc: 69.87%
Modelo guardado para Fold 1 con precisi n de validaci n: 69.87%
Epoch 3/20, Train Loss: 2.7601, Train Acc: 67.90%, Val Loss: 2.7173, Val Acc: 71.88%
Modelo guardado para Fold 1 con precisi n de validaci n: 71.88%
Epoch 4/20, Train Loss: 2.7352, Train Acc: 69.92%, Val Loss: 2.7098, Val Acc: 71.67%
Epoch 5/20, Train Loss: 2.7070, Train Acc: 72.59%, Val Loss: 2.6783, Val Acc: 74.91%
Modelo guardado para Fold 1 con precisi n de validaci n: 74.91%
Epoch 6/20, Train Loss: 2.6958, Train Acc: 73.48%, Val Loss: 2.6754, Val Acc: 75.10%
Modelo guardado para Fold 1 con precisi n de validaci n: 75.10%
Epoch 7/20, Train Loss: 2.6913, Train Acc: 73.80%, Val Loss: 2.6744, Val Acc: 75.13%
Modelo guardado para Fold 1 con precisi n de validaci n: 75.13%
Epoch 8/20, Train Loss: 2.6889, Train Acc: 73.93%, Val Loss: 2.6744, Val Acc: 75.11%
Epoch 9/20, Train Loss: 2.6867, Train Acc: 74.10%, Val Loss: 2.6733, Val Acc: 75.28%
Modelo guardado para Fold 1 con precisi n de validaci n: 75.28%
Epoch 10/20, Train Loss: 2.6846, Train Acc: 74.30%, Val Loss: 2.6721, Val Acc: 75.21%
Epoch 11/20, Train Loss: 2.6844, Train Acc: 74.27%, Val Loss: 2.6760, Val Acc: 74.96%
Epoch 12/20, Train Loss: 2.6824, Train Acc: 74.44%, Val Loss: 2.6698, Val Acc: 75.47%
Modelo guardado para Fold 1 con precisi n de validaci n: 75.47%
Epoch 13/20, Train Loss: 2.6822, Train Acc: 74.41%, Val Loss: 2.6733, Val Acc: 75.14%
Epoch 14/20, Train Loss: 2.6812, Train Acc: 74.50%, Val Loss: 2.6690, Val Acc: 75.59%
Modelo guardado para Fold 1 con precisi n de validaci n: 75.59%
Epoch 15/20, Train Loss: 2.6813, Train Acc: 74.46%, Val Loss: 2.6807, Val Acc: 74.45%
Epoch 16/20, Train Loss: 2.6816, Train Acc: 74.44%, Val Loss: 2.6710, Val Acc: 75.34%
Epoch 17/20, Train Loss: 2.6794, Train Acc: 74.65%, Val Loss: 2.6709, Val Acc: 75.42%
Epoch 18/20, Train Loss: 2.6792, Train Acc: 74.65%, Val Loss: 2.6757, Val Acc: 74.92%
Epoch 19/20, Train Loss: 2.6797, Train Acc: 74.59%, Val Loss: 2.6744, Val Acc: 75.13%
Epoch 20/20, Train Loss: 2.6789, Train Acc: 74.70%, Val Loss: 2.6681, Val Acc: 75.64%
Modelo guardado para Fold 1 con precisi n de validaci n: 75.64%
Mejor precisi n de validaci n para Fold 1: 75.64%

--- Evaluaci n Fold 1 ---
Precisi n del modelo en el conjunto de prueba (Fold 1): 75.64%
M tricas por clase para Fold 1:
Clase A - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase B - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase C - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase D - Precisi n: 0.9548, Recall: 0.9643, F1-Score: 0.9595
Clase E - Precisi n: 0.9563, Recall: 0.9808, F1-Score: 0.9684
Clase F - Precisi n: 0.7342, Recall: 0.9933, F1-Score: 0.8443
Clase G - Precisi n: 0.9757, Recall: 0.9857, F1-Score: 0.9807
Clase H - Precisi n: 0.9801, Recall: 0.9845, F1-Score: 0.9823
Clase I - Precisi n: 0.9933, Recall: 0.9451, F1-Score: 0.9686
Clase J - Precisi n: 0.9280, Recall: 0.9636, F1-Score: 0.9455
Clase K - Precisi n: 0.9911, Recall: 0.9875, F1-Score: 0.9893
Clase L - Precisi n: 0.4779, Recall: 0.9980, F1-Score: 0.6463
Clase M - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase N - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase O - Precisi n: 0.4983, Recall: 0.9978, F1-Score: 0.6647
Clase P - Precisi n: 0.6843, Recall: 0.9233, F1-Score: 0.7860
Clase Q - Precisi n: 0.6634, Recall: 0.9926, F1-Score: 0.7953
Clase R - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase S - Precisi n: 0.6899, Recall: 0.9904, F1-Score: 0.8133
Clase T - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase U - Precisi n: 0.4665, Recall: 0.9897, F1-Score: 0.6341
Clase V - Precisi n: 0.9841, Recall: 0.9802, F1-Score: 0.9822
Clase W - Precisi n: 0.7933, Recall: 0.9712, F1-Score: 0.8733
Clase X - Precisi n: 0.8739, Recall: 0.9938, F1-Score: 0.9300
Clase Y - Precisi n: 0.6114, Recall: 0.9981, F1-Score: 0.7583
Clase Z - Precisi n: 0.9935, Recall: 0.9828, F1-Score: 0.9881
Clase space - Precisi n: 0.9229, Recall: 0.9818, F1-Score: 0.9514
Clase delete - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase nothing - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000

==================================================
Fold 2/5
==================================================

--- Entrenando Fold 2 ---
Epoch 1/20, Train Loss: 3.1029, Train Acc: 35.37%, Val Loss: 2.8396, Val Acc: 62.62%
Modelo guardado para Fold 2 con precisi n de validaci n: 62.62%
Epoch 2/20, Train Loss: 2.8240, Train Acc: 62.61%, Val Loss: 2.7676, Val Acc: 66.50%
Modelo guardado para Fold 2 con precisi n de validaci n: 66.50%
Epoch 3/20, Train Loss: 2.7805, Train Acc: 65.45%, Val Loss: 2.7563, Val Acc: 67.09%
Modelo guardado para Fold 2 con precisi n de validaci n: 67.09%
Epoch 4/20, Train Loss: 2.7640, Train Acc: 66.70%, Val Loss: 2.7230, Val Acc: 70.55%
Modelo guardado para Fold 2 con precisi n de validaci n: 70.55%
Epoch 5/20, Train Loss: 2.7305, Train Acc: 69.96%, Val Loss: 2.7167, Val Acc: 70.84%
Modelo guardado para Fold 2 con precisi n de validaci n: 70.84%
Epoch 6/20, Train Loss: 2.7277, Train Acc: 70.06%, Val Loss: 2.7137, Val Acc: 71.11%
Modelo guardado para Fold 2 con precisi n de validaci n: 71.11%
Epoch 7/20, Train Loss: 2.7250, Train Acc: 70.26%, Val Loss: 2.7173, Val Acc: 70.89%
Epoch 8/20, Train Loss: 2.7232, Train Acc: 70.37%, Val Loss: 2.7141, Val Acc: 71.16%
Modelo guardado para Fold 2 con precisi n de validaci n: 71.16%
Epoch 9/20, Train Loss: 2.7227, Train Acc: 70.39%, Val Loss: 2.7195, Val Acc: 70.62%
Epoch 10/20, Train Loss: 2.7226, Train Acc: 70.34%, Val Loss: 2.7132, Val Acc: 71.25%
Modelo guardado para Fold 2 con precisi n de validaci n: 71.25%
Epoch 11/20, Train Loss: 2.7216, Train Acc: 70.44%, Val Loss: 2.7131, Val Acc: 71.15%
Epoch 12/20, Train Loss: 2.7207, Train Acc: 70.53%, Val Loss: 2.7112, Val Acc: 71.31%
Modelo guardado para Fold 2 con precisi n de validaci n: 71.31%
Epoch 13/20, Train Loss: 2.7201, Train Acc: 70.57%, Val Loss: 2.7113, Val Acc: 71.34%
Modelo guardado para Fold 2 con precisi n de validaci n: 71.34%
Epoch 14/20, Train Loss: 2.7204, Train Acc: 70.52%, Val Loss: 2.7120, Val Acc: 71.29%
Epoch 15/20, Train Loss: 2.7195, Train Acc: 70.61%, Val Loss: 2.7110, Val Acc: 71.31%
Epoch 16/20, Train Loss: 2.7198, Train Acc: 70.55%, Val Loss: 2.7128, Val Acc: 71.13%
Epoch 17/20, Train Loss: 2.7189, Train Acc: 70.67%, Val Loss: 2.7116, Val Acc: 71.32%
Epoch 18/20, Train Loss: 2.7187, Train Acc: 70.68%, Val Loss: 2.7122, Val Acc: 71.27%
Epoch 19/20, Train Loss: 2.7185, Train Acc: 70.67%, Val Loss: 2.7134, Val Acc: 71.13%
Epoch 20/20, Train Loss: 2.7179, Train Acc: 70.73%, Val Loss: 2.7115, Val Acc: 71.29%
Mejor precisi n de validaci n para Fold 2: 71.34%

--- Evaluaci n Fold 2 ---
Precisi n del modelo en el conjunto de prueba (Fold 2): 71.34%
M tricas por clase para Fold 2:
Clase A - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase B - Precisi n: 0.5145, Recall: 1.0000, F1-Score: 0.6794
Clase C - Precisi n: 0.9694, Recall: 0.9955, F1-Score: 0.9823
Clase D - Precisi n: 0.9450, Recall: 0.9698, F1-Score: 0.9572
Clase E - Precisi n: 0.9733, Recall: 0.9887, F1-Score: 0.9809
Clase F - Precisi n: 0.9840, Recall: 0.9857, F1-Score: 0.9849
Clase G - Precisi n: 0.9802, Recall: 0.9900, F1-Score: 0.9851
Clase H - Precisi n: 0.9793, Recall: 0.9895, F1-Score: 0.9844
Clase I - Precisi n: 0.9845, Recall: 0.9549, F1-Score: 0.9695
Clase J - Precisi n: 0.9959, Recall: 0.9621, F1-Score: 0.9787
Clase K - Precisi n: 0.2408, Recall: 0.9960, F1-Score: 0.3879
Clase L - Precisi n: 1.0000, Recall: 1.0000, F1-Score: 1.0000
Clase M - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase N - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase O - Precisi n: 0.9792, Recall: 0.9833, F1-Score: 0.9812
Clase P - Precisi n: 0.4475, Recall: 0.9869, F1-Score: 0.6158
Clase Q - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase R - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase S - Precisi n: 0.6906, Recall: 0.9901, F1-Score: 0.8137
Clase T - Precisi n: 0.5149, Recall: 0.9890, F1-Score: 0.6772
Clase U - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase V - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase W - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase X - Precisi n: 0.9587, Recall: 0.9905, F1-Score: 0.9744
Clase Y - Precisi n: 0.7008, Recall: 0.9923, F1-Score: 0.8215
Clase Z - Precisi n: 0.9959, Recall: 0.9780, F1-Score: 0.9869
Clase space - Precisi n: 0.9470, Recall: 0.9682, F1-Score: 0.9575
Clase delete - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase nothing - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000

==================================================
Fold 3/5
==================================================

--- Entrenando Fold 3 ---
Epoch 1/20, Train Loss: 3.1385, Train Acc: 31.09%, Val Loss: 2.9441, Val Acc: 51.18%
Modelo guardado para Fold 3 con precisi n de validaci n: 51.18%
Epoch 2/20, Train Loss: 2.8920, Train Acc: 55.60%, Val Loss: 2.8378, Val Acc: 59.44%
Modelo guardado para Fold 3 con precisi n de validaci n: 59.44%
Epoch 3/20, Train Loss: 2.8439, Train Acc: 59.14%, Val Loss: 2.8346, Val Acc: 59.44%
Epoch 4/20, Train Loss: 2.8217, Train Acc: 61.00%, Val Loss: 2.7993, Val Acc: 62.66%
Modelo guardado para Fold 3 con precisi n de validaci n: 62.66%
Epoch 5/20, Train Loss: 2.8062, Train Acc: 62.26%, Val Loss: 2.7946, Val Acc: 63.00%
Modelo guardado para Fold 3 con precisi n de validaci n: 63.00%
Epoch 6/20, Train Loss: 2.7849, Train Acc: 64.41%, Val Loss: 2.7589, Val Acc: 66.64%
Modelo guardado para Fold 3 con precisi n de validaci n: 66.64%
Epoch 7/20, Train Loss: 2.7660, Train Acc: 66.20%, Val Loss: 2.7577, Val Acc: 66.72%
Modelo guardado para Fold 3 con precisi n de validaci n: 66.72%
Epoch 8/20, Train Loss: 2.7636, Train Acc: 66.35%, Val Loss: 2.7594, Val Acc: 66.54%
Epoch 9/20, Train Loss: 2.7404, Train Acc: 68.74%, Val Loss: 2.7323, Val Acc: 69.30%
Modelo guardado para Fold 3 con precisi n de validaci n: 69.30%
Epoch 10/20, Train Loss: 2.7338, Train Acc: 69.32%, Val Loss: 2.7281, Val Acc: 69.69%
Modelo guardado para Fold 3 con precisi n de validaci n: 69.69%
Epoch 11/20, Train Loss: 2.7315, Train Acc: 69.50%, Val Loss: 2.7287, Val Acc: 69.65%
Epoch 12/20, Train Loss: 2.7303, Train Acc: 69.58%, Val Loss: 2.7268, Val Acc: 69.82%
Modelo guardado para Fold 3 con precisi n de validaci n: 69.82%
Epoch 13/20, Train Loss: 2.7296, Train Acc: 69.68%, Val Loss: 2.7273, Val Acc: 69.74%
Epoch 14/20, Train Loss: 2.7275, Train Acc: 69.85%, Val Loss: 2.7262, Val Acc: 69.87%
Modelo guardado para Fold 3 con precisi n de validaci n: 69.87%
Epoch 15/20, Train Loss: 2.7282, Train Acc: 69.75%, Val Loss: 2.7255, Val Acc: 69.84%
Epoch 16/20, Train Loss: 2.7267, Train Acc: 69.89%, Val Loss: 2.7263, Val Acc: 69.79%
Epoch 17/20, Train Loss: 2.7275, Train Acc: 69.83%, Val Loss: 2.7250, Val Acc: 69.92%
Modelo guardado para Fold 3 con precisi n de validaci n: 69.92%
Epoch 18/20, Train Loss: 2.7257, Train Acc: 69.96%, Val Loss: 2.7261, Val Acc: 69.88%
Epoch 19/20, Train Loss: 2.7252, Train Acc: 69.99%, Val Loss: 2.7294, Val Acc: 69.53%
Epoch 20/20, Train Loss: 2.7254, Train Acc: 69.98%, Val Loss: 2.7257, Val Acc: 69.83%
Mejor precisi n de validaci n para Fold 3: 69.92%

--- Evaluaci n Fold 3 ---
Precisi n del modelo en el conjunto de prueba (Fold 3): 69.92%
M tricas por clase para Fold 3:
Clase A - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase B - Precisi n: 0.5512, Recall: 1.0000, F1-Score: 0.7107
Clase C - Precisi n: 0.9746, Recall: 0.9871, F1-Score: 0.9808
Clase D - Precisi n: 0.9828, Recall: 0.9442, F1-Score: 0.9631
Clase E - Precisi n: 0.9642, Recall: 0.9773, F1-Score: 0.9707
Clase F - Precisi n: 0.9915, Recall: 0.9949, F1-Score: 0.9932
Clase G - Precisi n: 0.9831, Recall: 0.9957, F1-Score: 0.9894
Clase H - Precisi n: 0.9916, Recall: 0.9958, F1-Score: 0.9937
Clase I - Precisi n: 0.9690, Recall: 0.9358, F1-Score: 0.9521
Clase J - Precisi n: 0.9377, Recall: 0.9698, F1-Score: 0.9535
Clase K - Precisi n: 0.9522, Recall: 0.9890, F1-Score: 0.9702
Clase L - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase M - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase N - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase O - Precisi n: 0.9526, Recall: 0.9914, F1-Score: 0.9716
Clase P - Precisi n: 0.8759, Recall: 0.9045, F1-Score: 0.8900
Clase Q - Precisi n: 0.7409, Recall: 0.9907, F1-Score: 0.8478
Clase R - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase S - Precisi n: 0.4453, Recall: 0.9869, F1-Score: 0.6137
Clase T - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase U - Precisi n: 0.3010, Recall: 0.9919, F1-Score: 0.4618
Clase V - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase W - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase X - Precisi n: 0.3614, Recall: 0.9859, F1-Score: 0.5289
Clase Y - Precisi n: 0.6341, Recall: 1.0000, F1-Score: 0.7761
Clase Z - Precisi n: 0.7304, Recall: 0.9889, F1-Score: 0.8402
Clase space - Precisi n: 0.9472, Recall: 0.9758, F1-Score: 0.9613
Clase delete - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase nothing - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000

==================================================
Fold 4/5
==================================================

--- Entrenando Fold 4 ---
Epoch 1/20, Train Loss: 3.1055, Train Acc: 34.57%, Val Loss: 2.8776, Val Acc: 57.87%
Modelo guardado para Fold 4 con precisi n de validaci n: 57.87%
Epoch 2/20, Train Loss: 2.8392, Train Acc: 60.75%, Val Loss: 2.7566, Val Acc: 67.59%
Modelo guardado para Fold 4 con precisi n de validaci n: 67.59%
Epoch 3/20, Train Loss: 2.7535, Train Acc: 68.30%, Val Loss: 2.7117, Val Acc: 71.66%
Modelo guardado para Fold 4 con precisi n de validaci n: 71.66%
Epoch 4/20, Train Loss: 2.7256, Train Acc: 70.63%, Val Loss: 2.7090, Val Acc: 71.78%
Modelo guardado para Fold 4 con precisi n de validaci n: 71.78%
Epoch 5/20, Train Loss: 2.7197, Train Acc: 70.95%, Val Loss: 2.7057, Val Acc: 71.96%
Modelo guardado para Fold 4 con precisi n de validaci n: 71.96%
Epoch 6/20, Train Loss: 2.7162, Train Acc: 71.19%, Val Loss: 2.7041, Val Acc: 72.09%
Modelo guardado para Fold 4 con precisi n de validaci n: 72.09%
Epoch 7/20, Train Loss: 2.7145, Train Acc: 71.28%, Val Loss: 2.7039, Val Acc: 72.08%
Epoch 8/20, Train Loss: 2.6967, Train Acc: 73.19%, Val Loss: 2.6772, Val Acc: 74.77%
Modelo guardado para Fold 4 con precisi n de validaci n: 74.77%
Epoch 9/20, Train Loss: 2.6837, Train Acc: 74.36%, Val Loss: 2.6774, Val Acc: 74.81%
Modelo guardado para Fold 4 con precisi n de validaci n: 74.81%
Epoch 10/20, Train Loss: 2.6819, Train Acc: 74.51%, Val Loss: 2.6763, Val Acc: 74.86%
Modelo guardado para Fold 4 con precisi n de validaci n: 74.86%
Epoch 11/20, Train Loss: 2.6813, Train Acc: 74.50%, Val Loss: 2.6768, Val Acc: 74.91%
Modelo guardado para Fold 4 con precisi n de validaci n: 74.91%
Epoch 12/20, Train Loss: 2.6801, Train Acc: 74.62%, Val Loss: 2.6743, Val Acc: 75.02%
Modelo guardado para Fold 4 con precisi n de validaci n: 75.02%
Epoch 13/20, Train Loss: 2.6806, Train Acc: 74.57%, Val Loss: 2.6750, Val Acc: 74.97%
Epoch 14/20, Train Loss: 2.6792, Train Acc: 74.70%, Val Loss: 2.6773, Val Acc: 74.80%
Epoch 15/20, Train Loss: 2.6789, Train Acc: 74.68%, Val Loss: 2.6743, Val Acc: 75.03%
Modelo guardado para Fold 4 con precisi n de validaci n: 75.03%
Epoch 16/20, Train Loss: 2.6787, Train Acc: 74.68%, Val Loss: 2.6732, Val Acc: 75.11%
Modelo guardado para Fold 4 con precisi n de validaci n: 75.11%
Epoch 17/20, Train Loss: 2.6777, Train Acc: 74.77%, Val Loss: 2.6725, Val Acc: 75.18%
Modelo guardado para Fold 4 con precisi n de validaci n: 75.18%
Epoch 18/20, Train Loss: 2.6780, Train Acc: 74.75%, Val Loss: 2.6733, Val Acc: 75.22%
Modelo guardado para Fold 4 con precisi n de validaci n: 75.22%
Epoch 19/20, Train Loss: 2.6769, Train Acc: 74.84%, Val Loss: 2.6633, Val Acc: 76.06%
Modelo guardado para Fold 4 con precisi n de validaci n: 76.06%
Epoch 20/20, Train Loss: 2.6621, Train Acc: 76.36%, Val Loss: 2.6527, Val Acc: 77.14%
Modelo guardado para Fold 4 con precisi n de validaci n: 77.14%
Mejor precisi n de validaci n para Fold 4: 77.14%

--- Evaluaci n Fold 4 ---
Precisi n del modelo en el conjunto de prueba (Fold 4): 77.14%
M tricas por clase para Fold 4:
Clase A - Precisi n: 0.6844, Recall: 0.9861, F1-Score: 0.8080
Clase B - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase C - Precisi n: 0.9616, Recall: 1.0000, F1-Score: 0.9804
Clase D - Precisi n: 0.9793, Recall: 0.9556, F1-Score: 0.9673
Clase E - Precisi n: 0.9389, Recall: 0.9958, F1-Score: 0.9665
Clase F - Precisi n: 0.8986, Recall: 0.9761, F1-Score: 0.9358
Clase G - Precisi n: 0.9509, Recall: 0.9921, F1-Score: 0.9710
Clase H - Precisi n: 0.9084, Recall: 0.9922, F1-Score: 0.9485
Clase I - Precisi n: 0.9866, Recall: 0.9506, F1-Score: 0.9683
Clase J - Precisi n: 0.9889, Recall: 0.9657, F1-Score: 0.9772
Clase K - Precisi n: 0.5391, Recall: 0.9857, F1-Score: 0.6970
Clase L - Precisi n: 0.7025, Recall: 0.9980, F1-Score: 0.8246
Clase M - Precisi n: 0.4664, Recall: 0.7941, F1-Score: 0.5877
Clase N - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase O - Precisi n: 0.9579, Recall: 0.9886, F1-Score: 0.9730
Clase P - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase Q - Precisi n: 0.5588, Recall: 0.9953, F1-Score: 0.7157
Clase R - Precisi n: 0.4457, Recall: 0.9958, F1-Score: 0.6158
Clase S - Precisi n: 0.9183, Recall: 0.9797, F1-Score: 0.9480
Clase T - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase U - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase V - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase W - Precisi n: 0.5562, Recall: 0.9778, F1-Score: 0.7091
Clase X - Precisi n: 0.8957, Recall: 0.9883, F1-Score: 0.9397
Clase Y - Precisi n: 1.0000, Recall: 0.9921, F1-Score: 0.9960
Clase Z - Precisi n: 0.9577, Recall: 0.9794, F1-Score: 0.9684
Clase space - Precisi n: 0.9104, Recall: 0.9621, F1-Score: 0.9356
Clase delete - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase nothing - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000

==================================================
Fold 5/5
==================================================

--- Entrenando Fold 5 ---
Epoch 1/20, Train Loss: 3.1521, Train Acc: 29.39%, Val Loss: 2.9691, Val Acc: 47.36%
Modelo guardado para Fold 5 con precisi n de validaci n: 47.36%
Epoch 2/20, Train Loss: 2.9567, Train Acc: 48.43%, Val Loss: 2.8999, Val Acc: 53.16%
Modelo guardado para Fold 5 con precisi n de validaci n: 53.16%
Epoch 3/20, Train Loss: 2.8946, Train Acc: 54.14%, Val Loss: 2.8388, Val Acc: 59.52%
Modelo guardado para Fold 5 con precisi n de validaci n: 59.52%
Epoch 4/20, Train Loss: 2.8414, Train Acc: 59.29%, Val Loss: 2.8183, Val Acc: 60.81%
Modelo guardado para Fold 5 con precisi n de validaci n: 60.81%
Epoch 5/20, Train Loss: 2.8120, Train Acc: 62.00%, Val Loss: 2.7566, Val Acc: 67.28%
Modelo guardado para Fold 5 con precisi n de validaci n: 67.28%
Epoch 6/20, Train Loss: 2.7688, Train Acc: 66.15%, Val Loss: 2.7501, Val Acc: 67.57%
Modelo guardado para Fold 5 con precisi n de validaci n: 67.57%
Epoch 7/20, Train Loss: 2.7629, Train Acc: 66.57%, Val Loss: 2.7524, Val Acc: 67.40%
Epoch 8/20, Train Loss: 2.7600, Train Acc: 66.73%, Val Loss: 2.7499, Val Acc: 67.56%
Epoch 9/20, Train Loss: 2.7579, Train Acc: 66.94%, Val Loss: 2.7540, Val Acc: 67.05%
Epoch 10/20, Train Loss: 2.7576, Train Acc: 66.91%, Val Loss: 2.7445, Val Acc: 67.91%
Modelo guardado para Fold 5 con precisi n de validaci n: 67.91%
Epoch 11/20, Train Loss: 2.7557, Train Acc: 67.07%, Val Loss: 2.7463, Val Acc: 67.94%
Modelo guardado para Fold 5 con precisi n de validaci n: 67.94%
Epoch 12/20, Train Loss: 2.7553, Train Acc: 67.08%, Val Loss: 2.7435, Val Acc: 68.07%
Modelo guardado para Fold 5 con precisi n de validaci n: 68.07%
Epoch 13/20, Train Loss: 2.7520, Train Acc: 67.40%, Val Loss: 2.7150, Val Acc: 70.92%
Modelo guardado para Fold 5 con precisi n de validaci n: 70.92%
Epoch 14/20, Train Loss: 2.7269, Train Acc: 69.95%, Val Loss: 2.7132, Val Acc: 71.15%
Modelo guardado para Fold 5 con precisi n de validaci n: 71.15%
Epoch 15/20, Train Loss: 2.7248, Train Acc: 70.11%, Val Loss: 2.7116, Val Acc: 71.27%
Modelo guardado para Fold 5 con precisi n de validaci n: 71.27%
Epoch 16/20, Train Loss: 2.7235, Train Acc: 70.24%, Val Loss: 2.7123, Val Acc: 71.17%
Epoch 17/20, Train Loss: 2.7240, Train Acc: 70.16%, Val Loss: 2.7113, Val Acc: 71.27%
Epoch 18/20, Train Loss: 2.7231, Train Acc: 70.24%, Val Loss: 2.7139, Val Acc: 71.00%
Epoch 19/20, Train Loss: 2.7231, Train Acc: 70.24%, Val Loss: 2.7112, Val Acc: 71.28%
Modelo guardado para Fold 5 con precisi n de validaci n: 71.28%
Epoch 20/20, Train Loss: 2.7091, Train Acc: 71.66%, Val Loss: 2.6881, Val Acc: 73.68%
Modelo guardado para Fold 5 con precisi n de validaci n: 73.68%
Mejor precisi n de validaci n para Fold 5: 73.68%

--- Evaluaci n Fold 5 ---
Precisi n del modelo en el conjunto de prueba (Fold 5): 73.68%
M tricas por clase para Fold 5:
Clase A - Precisi n: 0.9613, Recall: 0.9781, F1-Score: 0.9696
Clase B - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase C - Precisi n: 0.5714, Recall: 0.9856, F1-Score: 0.7234
Clase D - Precisi n: 0.7899, Recall: 0.9711, F1-Score: 0.8712
Clase E - Precisi n: 0.5271, Recall: 0.9937, F1-Score: 0.6889
Clase F - Precisi n: 0.8801, Recall: 0.9864, F1-Score: 0.9302
Clase G - Precisi n: 0.9916, Recall: 0.9937, F1-Score: 0.9927
Clase H - Precisi n: 0.9856, Recall: 0.9917, F1-Score: 0.9886
Clase I - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase J - Precisi n: 0.7121, Recall: 0.9831, F1-Score: 0.8259
Clase K - Precisi n: 0.4820, Recall: 0.9907, F1-Score: 0.6485
Clase L - Precisi n: 1.0000, Recall: 1.0000, F1-Score: 1.0000
Clase M - Precisi n: 0.5444, Recall: 0.9453, F1-Score: 0.6910
Clase N - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase O - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase P - Precisi n: 0.9566, Recall: 0.9475, F1-Score: 0.9520
Clase Q - Precisi n: 0.9492, Recall: 0.9558, F1-Score: 0.9525
Clase R - Precisi n: 0.3814, Recall: 0.9858, F1-Score: 0.5500
Clase S - Precisi n: 0.8362, Recall: 0.9839, F1-Score: 0.9041
Clase T - Precisi n: 0.9977, Recall: 0.9865, F1-Score: 0.9921
Clase U - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase V - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase W - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase X - Precisi n: 0.9614, Recall: 0.9925, F1-Score: 0.9767
Clase Y - Precisi n: 0.9887, Recall: 0.9925, F1-Score: 0.9906
Clase Z - Precisi n: 0.9736, Recall: 0.9866, F1-Score: 0.9800
Clase space - Precisi n: 0.5231, Recall: 0.9850, F1-Score: 0.6833
Clase delete - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase nothing - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Epoch 1/40, Train Loss: 3.1356, Train Acc: 32.02%, Val Loss: 2.9108, Val Acc: 55.77%
Modelo guardado con precisi n de validaci n: 55.77%
Epoch 2/40, Train Loss: 2.8507, Train Acc: 60.66%, Val Loss: 2.7620, Val Acc: 68.18%
Modelo guardado con precisi n de validaci n: 68.18%
Epoch 3/40, Train Loss: 2.7732, Train Acc: 66.97%, Val Loss: 2.7418, Val Acc: 68.97%
Modelo guardado con precisi n de validaci n: 68.97%
Epoch 4/40, Train Loss: 2.7532, Train Acc: 68.05%, Val Loss: 2.7381, Val Acc: 69.00%
Modelo guardado con precisi n de validaci n: 69.00%
Epoch 5/40, Train Loss: 2.7477, Train Acc: 68.28%, Val Loss: 2.7354, Val Acc: 69.16%
Modelo guardado con precisi n de validaci n: 69.16%
Epoch 6/40, Train Loss: 2.7433, Train Acc: 68.61%, Val Loss: 2.7331, Val Acc: 69.28%
Modelo guardado con precisi n de validaci n: 69.28%
Epoch 7/40, Train Loss: 2.7414, Train Acc: 68.67%, Val Loss: 2.7309, Val Acc: 69.35%
Modelo guardado con precisi n de validaci n: 69.35%
Epoch 8/40, Train Loss: 2.7397, Train Acc: 68.75%, Val Loss: 2.7310, Val Acc: 69.40%
Modelo guardado con precisi n de validaci n: 69.40%
Epoch 9/40, Train Loss: 2.7395, Train Acc: 68.77%, Val Loss: 2.7321, Val Acc: 69.30%
Epoch 10/40, Train Loss: 2.7381, Train Acc: 68.86%, Val Loss: 2.7314, Val Acc: 69.36%
Epoch 11/40, Train Loss: 2.7376, Train Acc: 68.84%, Val Loss: 2.7307, Val Acc: 69.36%
Epoch 12/40, Train Loss: 2.7366, Train Acc: 68.97%, Val Loss: 2.7288, Val Acc: 69.54%
Modelo guardado con precisi n de validaci n: 69.54%
Epoch 13/40, Train Loss: 2.7357, Train Acc: 69.04%, Val Loss: 2.7301, Val Acc: 69.43%
Epoch 14/40, Train Loss: 2.7356, Train Acc: 69.00%, Val Loss: 2.7300, Val Acc: 69.49%
Epoch 15/40, Train Loss: 2.7344, Train Acc: 69.12%, Val Loss: 2.7293, Val Acc: 69.57%
Modelo guardado con precisi n de validaci n: 69.57%
Epoch 16/40, Train Loss: 2.7342, Train Acc: 69.19%, Val Loss: 2.7302, Val Acc: 69.46%
Epoch 17/40, Train Loss: 2.7338, Train Acc: 69.19%, Val Loss: 2.7297, Val Acc: 69.46%
Epoch 18/40, Train Loss: 2.7336, Train Acc: 69.18%, Val Loss: 2.7277, Val Acc: 69.70%
Modelo guardado con precisi n de validaci n: 69.70%
Epoch 19/40, Train Loss: 2.7338, Train Acc: 69.16%, Val Loss: 2.7290, Val Acc: 69.55%
Epoch 20/40, Train Loss: 2.7329, Train Acc: 69.23%, Val Loss: 2.7281, Val Acc: 69.56%
Epoch 21/40, Train Loss: 2.7336, Train Acc: 69.15%, Val Loss: 2.7287, Val Acc: 69.60%
Epoch 22/40, Train Loss: 2.7326, Train Acc: 69.28%, Val Loss: 2.7271, Val Acc: 69.75%
Modelo guardado con precisi n de validaci n: 69.75%
Epoch 23/40, Train Loss: 2.7328, Train Acc: 69.25%, Val Loss: 2.7284, Val Acc: 69.60%
Epoch 24/40, Train Loss: 2.7322, Train Acc: 69.26%, Val Loss: 2.7277, Val Acc: 69.62%
Epoch 25/40, Train Loss: 2.7320, Train Acc: 69.31%, Val Loss: 2.7276, Val Acc: 69.60%
Epoch 26/40, Train Loss: 2.7314, Train Acc: 69.35%, Val Loss: 2.7263, Val Acc: 69.72%
Epoch 27/40, Train Loss: 2.7315, Train Acc: 69.33%, Val Loss: 2.7259, Val Acc: 69.80%
Modelo guardado con precisi n de validaci n: 69.80%
Epoch 28/40, Train Loss: 2.7308, Train Acc: 69.41%, Val Loss: 2.7272, Val Acc: 69.73%
Epoch 29/40, Train Loss: 2.7315, Train Acc: 69.33%, Val Loss: 2.7270, Val Acc: 69.68%
Epoch 30/40, Train Loss: 2.7301, Train Acc: 69.45%, Val Loss: 2.7250, Val Acc: 69.81%
Modelo guardado con precisi n de validaci n: 69.81%
Epoch 31/40, Train Loss: 2.7078, Train Acc: 71.76%, Val Loss: 2.6945, Val Acc: 72.97%
Modelo guardado con precisi n de validaci n: 72.97%
Epoch 32/40, Train Loss: 2.6945, Train Acc: 73.10%, Val Loss: 2.6965, Val Acc: 72.76%
Epoch 33/40, Train Loss: 2.6949, Train Acc: 73.03%, Val Loss: 2.6931, Val Acc: 73.13%
Modelo guardado con precisi n de validaci n: 73.13%
Epoch 34/40, Train Loss: 2.6946, Train Acc: 73.05%, Val Loss: 2.6930, Val Acc: 73.15%
Modelo guardado con precisi n de validaci n: 73.15%
Epoch 35/40, Train Loss: 2.6936, Train Acc: 73.12%, Val Loss: 2.6915, Val Acc: 73.25%
Modelo guardado con precisi n de validaci n: 73.25%
Epoch 36/40, Train Loss: 2.6943, Train Acc: 73.05%, Val Loss: 2.6926, Val Acc: 73.15%
Epoch 37/40, Train Loss: 2.6927, Train Acc: 73.22%, Val Loss: 2.6919, Val Acc: 73.18%
Epoch 38/40, Train Loss: 2.6946, Train Acc: 73.01%, Val Loss: 2.6938, Val Acc: 73.00%
Epoch 39/40, Train Loss: 2.6931, Train Acc: 73.17%, Val Loss: 2.6923, Val Acc: 73.17%
Epoch 40/40, Train Loss: 2.6937, Train Acc: 73.11%, Val Loss: 2.6938, Val Acc: 73.03%
Precisi n del modelo en el conjunto de prueba: 74.29%
Clase A - Precisi n: 0.7876, Recall: 0.9861, F1-Score: 0.8758
Clase B - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase C - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase D - Precisi n: 0.8505, Recall: 0.9864, F1-Score: 0.9134
Clase E - Precisi n: 0.7283, Recall: 0.9749, F1-Score: 0.8338
Clase F - Precisi n: 0.7944, Recall: 0.9930, F1-Score: 0.8827
Clase G - Precisi n: 0.9769, Recall: 1.0000, F1-Score: 0.9883
Clase H - Precisi n: 0.9948, Recall: 0.9948, F1-Score: 0.9948
Clase I - Precisi n: 0.9967, Recall: 0.9443, F1-Score: 0.9698
Clase J - Precisi n: 0.9894, Recall: 0.9689, F1-Score: 0.9791
Clase K - Precisi n: 0.3363, Recall: 0.9948, F1-Score: 0.5026
Clase L - Precisi n: 0.5714, Recall: 1.0000, F1-Score: 0.7273
Clase M - Precisi n: 0.5097, Recall: 0.9767, F1-Score: 0.6699
Clase N - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase O - Precisi n: 0.6327, Recall: 0.9972, F1-Score: 0.7742
Clase P - Precisi n: 0.9902, Recall: 0.8938, F1-Score: 0.9395
Clase Q - Precisi n: 0.8975, Recall: 1.0000, F1-Score: 0.9460
Clase R - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase S - Precisi n: 0.9791, Recall: 0.9868, F1-Score: 0.9829
Clase T - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase U - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase V - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase W - Precisi n: 0.5638, Recall: 0.9899, F1-Score: 0.7185
Clase X - Precisi n: 0.6480, Recall: 0.9939, F1-Score: 0.7845
Clase Y - Precisi n: 0.9924, Recall: 1.0000, F1-Score: 0.9962
Clase Z - Precisi n: 0.9693, Recall: 0.9830, F1-Score: 0.9761
Clase space - Precisi n: 0.9434, Recall: 0.9690, F1-Score: 0.9560
Clase delete - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000
Clase nothing - Precisi n: 0.0000, Recall: 0.0000, F1-Score: 0.0000

==================================================
Rendimiento promedio de la validaci n cruzada (5-fold): 73.55%
==================================================
Modelo guardado como modelo_asl.pkl

[Done] exited with code=0 in 5126.704 seconds


